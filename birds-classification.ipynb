{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport pandas as pd\nimport torch\nimport time\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as T\nimport torchvision.models as models\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import RandomSampler\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 64\ntarget_size = (224*224*3)\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  \n    transforms.ToTensor(),  \n])\n\ntrain_dir = \"/kaggle/input/100-bird-species/train/\"\ntest_dir = \"/kaggle/input/100-bird-species/test/\"\nval_dir = \"/kaggle/input/100-bird-species/valid/\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using {device} device\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    total_loss = 0\n\n    for X, y in dataloader:\n        X, y = X.to(device), y.to(device)\n        \n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        total_loss += loss.item()\n\n    return total_loss / size\n\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n\n    test_loss /= size\n    correct /= size\n\n    return test_loss, 100 * correct","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_and_evaluate_model(model, train_dataloader, test_dataloader, loss_fn, optimizer, n_epochs):\n    losses_train = []\n    losses_test = []\n    accuracies_test = []\n\n    for t in range(n_epochs):\n        print(f\"Epoch {t+1}\\n-------------------------------\")\n        loss_train = train(train_dataloader, model, loss_fn, optimizer)\n        loss_test, accuracy_test = test(test_dataloader, model, loss_fn)\n        print(\"Loss train:\", loss_train, \", loss test:\", loss_test, \", accuracy test:\", accuracy_test)\n\n        losses_train.append(loss_train)\n        losses_test.append(loss_test)\n        accuracies_test.append(accuracy_test)\n\n    print(\"Done!\")\n    return model, losses_train, losses_test, accuracies_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_time = time.time()\n\n# Define the ResNet model\nresnet = models.resnet101(weights=True)\nresnet.fc = nn.Linear(resnet.fc.in_features, 525)  # Adjust for number of classes in the Dataset\n\n# Freeze all layers\nfor param in resnet.parameters():\n    param.requires_grad = False\n\n# Unfreeze the fully connected layer\nfor param in resnet.fc.parameters():\n    param.requires_grad = True\n\n# Define transformations\nresnet_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((224, 224)),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load data using ImageFolder\ntrain_data_resnet = ImageFolder(root=train_dir, transform=resnet_transform)\nvalid_data_resnet = ImageFolder(root=val_dir, transform=resnet_transform)\n\n# Create DataLoader instances\ntrain_dataloader = DataLoader(train_data_resnet, batch_size=32, shuffle=True)\nvalid_dataloader = DataLoader(valid_data_resnet, batch_size=32, shuffle=False)\n\n# Define loss function and optimizer\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet.fc.parameters(), lr=1e-3)  # Optimize only the last layer\n\n# Move model to the appropriate device\nresnet.to(device)\n\n# Call the training and evaluation function\nresnet, resnet_losses_train, resnet_losses_test, resnet_accuracies_test = train_and_evaluate_model(\n    model=resnet,\n    train_dataloader=train_dataloader,\n    test_dataloader=valid_dataloader,\n    loss_fn=loss_fn,\n    optimizer=optimizer,\n    n_epochs=10\n)\n\nend_time = time.time()\nexecution_time = end_time - start_time\nprint(f'Время выполнения: {execution_time} секунд')\n\n# Plotting\nplt.plot(resnet_losses_train, label=\"Train loss\")\nplt.plot(resnet_losses_test, label=\"Test loss\")\nplt.xlabel(\"Epoch\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save model's state_dict\ntorch.save(resnet.state_dict(), 'model_weights.pth')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(resnet_accuracies_test, label=\"Test loss\")\nplt.xlabel(\"Epoch\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}